[{"id":0,"href":"/blog/","title":"a dystopian journey into the heart of tech","parent":"","content":"","description":""},{"id":1,"href":"/blog/posts/mutex-vs-semaphore/","title":"Mutex vs Semaphore","parent":"Posts","content":" Mutex vs Semaphore: The Lesser of Two Evils Mutexes and semaphores are like siblings in the synchronization primitives family — one a stickler for rules (mutex), the other more lenient but equally capable of chaos when misused (semaphore). I\u0026rsquo;ll try to dive into this family drama with a sprinkle of snark, to explore their strengths, weaknesses.. And, both drive me nuts when misused.\nThe Boring Theory Mutex A mutex, short for \u0026ldquo;mutual exclusion,\u0026rdquo; is like that one friend who insists on being the only one to use their fancy pen. It\u0026rsquo;s a locking mechanism that ensures only one thread can access a shared resource at a time.\nsequenceDiagram participant T1 as Thread 1 participant M as Mutex participant R as Resource participant T2 as Thread 2 T1-\u0026gt;\u0026gt;M: Lock M-\u0026gt;\u0026gt;T1: Granted T1-\u0026gt;\u0026gt;R: Access T2-\u0026gt;\u0026gt;M: Lock (Blocked) T1-\u0026gt;\u0026gt;R: Finish T1-\u0026gt;\u0026gt;M: Unlock M-\u0026gt;\u0026gt;T2: Granted T2-\u0026gt;\u0026gt;R: Access Semaphore A semaphore, on the other hand, is a signaling mechanism. It can control access by multiple threads using a counter. When the counter is greater than zero, a thread can proceed and decrement the counter. When it hits zero, threads block until the counter is incremented.\nLoosely speaking, a semaphore is like a nightclub bouncer with a clicker. It allows a specified number of threads to access a resource concurrently. When the limit is reached, newcomers have to wait until someone leaves.\nsequenceDiagram participant T1 as Thread 1 participant T2 as Thread 2 participant S as Semaphore (2) participant R as Resource participant T3 as Thread 3 T1-\u0026gt;\u0026gt;S: Acquire S-\u0026gt;\u0026gt;T1: Granted (1 left) T2-\u0026gt;\u0026gt;S: Acquire S-\u0026gt;\u0026gt;T2: Granted (0 left) T1-\u0026gt;\u0026gt;R: Access T2-\u0026gt;\u0026gt;R: Access T3-\u0026gt;\u0026gt;S: Acquire (Blocked) T1-\u0026gt;\u0026gt;S: Release S-\u0026gt;\u0026gt;T3: Granted T3-\u0026gt;\u0026gt;R: Access The Good, The Bad, and The Ugly Mutex: When One Is the Loneliest Number (And That\u0026rsquo;s Good) Use a mutex when:\nYou have a critical section that absolutely must be executed by only one thread at a time. You need to protect shared data from race conditions. You want to ensure the atomicity of a complex operation. using System; using System.Threading; public class BankAccount { private decimal balance = 0; private readonly object lockObject = new object(); public void Deposit(decimal amount) { lock (lockObject) { // Critical section balance += amount; } } public bool Withdraw(decimal amount) { lock (lockObject) { if (balance \u0026gt;= amount) { balance -= amount; return true; } return false; } } } Semaphore: When You Need to Control the Party Use a semaphore when:\nYou want to limit the number of threads that can access a resource concurrently. You\u0026rsquo;re implementing a producer-consumer pattern. You need to synchronize access to a pool of resources. using System; using System.Collections.Generic; using System.Threading; public class Connection { // Connection implementation } public class ConnectionPool { private readonly List\u0026lt;Connection\u0026gt; connections = new List\u0026lt;Connection\u0026gt;(); private readonly SemaphoreSlim semaphore; public ConnectionPool(int maxConnections) { semaphore = new SemaphoreSlim(maxConnections, maxConnections); for (int i = 0; i \u0026lt; maxConnections; i++) { connections.Add(new Connection()); } } public async Task\u0026lt;Connection\u0026gt; GetConnectionAsync() { await semaphore.WaitAsync(); return connections[connections.Count - 1]; } public void ReleaseConnection(Connection connection) { connections.Add(connection); semaphore.Release(); } } The Pitfalls: Where Good Intentions Go to Die Now, let\u0026rsquo;s talk about \u0026lsquo;cases\u0026rsquo; when \u0026lsquo;some\u0026rsquo; of us manage to royally screw things up. Buckle up, because this is where it gets painful.\nDeadlocks: The Eternal Standoff Picture two threads, each holding a resource the other needs. They\u0026rsquo;re locked in a deadly embrace, waiting for the other to blink first. This, my friends, is a deadlock.\ngraph TD A[Thread A] --\u0026gt;|Holds| R1[Resource 1] B[Thread B] --\u0026gt;|Holds| R2[Resource 2] A --\u0026gt;|Wants| R2 B --\u0026gt;|Wants| R1 To avoid this nightmare:\nAlways acquire locks in a consistent order. Use timeouts when acquiring locks. Implement deadlock detection and recovery mechanisms. Priority Inversion: When the VIP Gets Stuck Behind the Bouncer Imagine a high-priority thread waiting for a low-priority thread to release a lock. Meanwhile, a medium-priority thread keeps preempting the low-priority thread. It\u0026rsquo;s like a VIP stuck behind the bouncer while regular patrons keep streaming in.\nTo mitigate this:\nUse priority inheritance protocols. Minimize the time locks are held. Consider lock-free algorithms for performance-critical sections. (your current and future peers will either thank you immensely or curse you out—depending on how well you understand and implement this. This is a world of dragons, fwiw.) and, for the love of all that’s holy, please go with the simpler option!! PLEASE!\nMaybe lets switch gears? Read-Write Locks: The Bookworm\u0026rsquo;s Paradise When you have many readers and few writers, a read-write lock can significantly improve performance.\nusing System; using System.Threading; using System.Threading.Tasks; public class AsyncReadWriteLock { private readonly SemaphoreSlim _readSemaphore = new SemaphoreSlim(1, 1); private readonly SemaphoreSlim _writeSemaphore = new SemaphoreSlim(1, 1); private int _readCount = 0; public async Task\u0026lt;IDisposable\u0026gt; ReadLockAsync(CancellationToken cancellationToken = default) { await _readSemaphore.WaitAsync(cancellationToken); try { if (Interlocked.Increment(ref _readCount) == 1) { await _writeSemaphore.WaitAsync(cancellationToken); } } finally { _readSemaphore.Release(); } return new AsyncDisposable(async () =\u0026gt; { await _readSemaphore.WaitAsync(cancellationToken); try { if (Interlocked.Decrement(ref _readCount) == 0) { _writeSemaphore.Release(); } } finally { _readSemaphore.Release(); } }); } public async Task\u0026lt;IDisposable\u0026gt; WriteLockAsync(CancellationToken cancellationToken = default) { await _writeSemaphore.WaitAsync(cancellationToken); return new AsyncDisposable(() =\u0026gt; Task.FromResult(_writeSemaphore.Release())); } private class AsyncDisposable : IDisposable { private readonly Func\u0026lt;Task\u0026gt; _releaseAction; private bool _isDisposed; public AsyncDisposable(Func\u0026lt;Task\u0026gt; releaseAction) { _releaseAction = releaseAction; } public void Dispose() { if (_isDisposed) return; _isDisposed = true; _releaseAction().GetAwaiter().GetResult(); } } } and that could be used in a potential real-world use case like this -\npublic class ThreadSafeCache { private readonly Dictionary\u0026lt;string, string\u0026gt; _cache = new Dictionary\u0026lt;string, string\u0026gt;(); private readonly AsyncReadWriteLock _lock = new AsyncReadWriteLock(); public async Task\u0026lt;string\u0026gt; GetOrAddAsync(string key, Func\u0026lt;Task\u0026lt;string\u0026gt;\u0026gt; valueFactory, CancellationToken cancellationToken = default) { using (await _lock.ReadLockAsync(cancellationToken)) { if (_cache.TryGetValue(key, out string value)) { return value; } } using (await _lock.WriteLockAsync(cancellationToken)) { // Double-check in case another thread added the value if (_cache.TryGetValue(key, out string value)) { return value; } string newValue = await valueFactory(); _cache[key] = newValue; return newValue; } } public async Task UpdateAsync(string key, string value, CancellationToken cancellationToken = default) { using (await _lock.WriteLockAsync(cancellationToken)) { _cache[key] = value; } } } And, a runsheet (atleast, for me) for these \u0026lsquo;real-world\u0026rsquo; use cases:\nCorrect Lock Usage: We properly release locks using using statements, ensuring they\u0026rsquo;re always released even if exceptions occur. Double-Checked Locking: We first check under a read lock, then under a write lock, minimizing the time spent holding the more expensive write lock. Async Operations: Both reading and writing support asynchronous operations, crucial for maintaining responsiveness in real-world applications. Cancellation Support: All methods accept a CancellationToken, allowing operations to be cancelled gracefully. Lock-Free Algorithms: Living on the Edge For the truly brave (or foolhardy), lock-free algorithms offer the promise of high performance without the overhead of locks. But beware, here be dragons.\nusing System; using System.Threading; public class LockFreeStack\u0026lt;T\u0026gt; { private class Node { public T Value; public Node Next; public int Version; public Node(T value, Node next, int version) { Value = value; Next = next; Version = version; } } private Node _head; private long _operationCount; public void Push(T value) { var newNode = new Node(value, null, 0); while (true) { var oldHead = _head; newNode.Next = oldHead; if (Interlocked.CompareExchange(ref _head, newNode, oldHead) == oldHead) { Interlocked.Increment(ref _operationCount); return; } Thread.Yield(); } } public bool TryPop(out T result) { while (true) { var oldHead = _head; if (oldHead == null) { result = default; return false; } var newHead = oldHead.Next; if (Interlocked.CompareExchange(ref _head, newHead, oldHead) == oldHead) { result = oldHead.Value; Interlocked.Increment(ref _operationCount); // Ensure the node can\u0026#39;t be reused until all ongoing operations that might have seen it complete SpinWait.SpinUntil(() =\u0026gt; Volatile.Read(ref _operationCount) % 2 == 0); return true; } Thread.Yield(); } } public long OperationCount =\u0026gt; Volatile.Read(ref _operationCount); } And, the runsheet here (again, atleast for me):\nABA Problem Mitigation! Operation Counting: The _operationCount field keeps track of the number of push and pop operations. This can be useful for monitoring and debugging purposes. Memory Ordering: Use Volatile.Read to ensure proper memory ordering when reading the operation count. Backoff Strategy: Use Thread.Yield() instead of busy-waiting, which can improve performance in high-contention scenarios by allowing other threads to make progress. Safe Memory Reclamation: The SpinWait.SpinUntil in TryPop ensures that a popped node isn\u0026rsquo;t immediately reused, preventing potential issues with ongoing operations. A potential application for lock-free algorithms? A logging system! Nothing can get busier, imho.\npublic class HighPerformanceLogger { private readonly LockFreeStack\u0026lt;LogEntry\u0026gt; _logBuffer = new LockFreeStack\u0026lt;LogEntry\u0026gt;(); private readonly Thread _logWriterThread; private volatile bool _isRunning = true; private readonly AutoResetEvent _newLogEvent = new AutoResetEvent(false); public HighPerformanceLogger() { _logWriterThread = new Thread(LogWriterLoop); _logWriterThread.Start(); } public void Log(string message, LogLevel level) { _logBuffer.Push(new LogEntry(message, level, DateTime.UtcNow)); _newLogEvent.Set(); } private void LogWriterLoop() { while (_isRunning) { if (_logBuffer.TryPop(out var logEntry)) { // In a real implementation, we\u0026#39;d write to a file or database Console.WriteLine($\u0026#34;[{logEntry.Timestamp:yyyy-MM-dd HH:mm:ss.fff}] [{logEntry.Level}] {logEntry.Message}\u0026#34;); } else { // Wait for a new log entry or a timeout. We coulduse `sleep` instead, well.. I don\u0026#39;t like ... sleep, in programming contenxt only though :p _newLogEvent.WaitOne(100); } } // Process any remaining logs after shutdown signal while (_logBuffer.TryPop(out var logEntry)) { Console.WriteLine($\u0026#34;[{logEntry.Timestamp:yyyy-MM-dd HH:mm:ss.fff}] [{logEntry.Level}] {logEntry.Message}\u0026#34;); } } public void Shutdown() { _isRunning = false; _newLogEvent.Set(); // Ensure the log writer thread wakes up _logWriterThread.Join(); _newLogEvent.Dispose(); } } public enum LogLevel { Debug, Info, Warning, Error, Critical } Event-Based Waiting: This allows the log writer thread to efficiently wait for new log entries without consuming CPU cycles. Decoupled Log Writing: The LogWriterLoop runs on a separate thread, processing log entries asynchronously. This ensures that logging doesn\u0026rsquo;t slow down the main application threads. Low-Latency: The \u0026rsquo;lock-free\u0026rsquo; nature of our stack means that logging operations (pushes) complete very quickly, minimizing the impact on latency-sensitive operations \u0026ndash; like, whatever it is your company does to save the world! Graceful Shutdown: The Shutdown method demonstrates how to safely stop the logging thread, ensuring all logs are processed before the application exits. So, what am I saying? imho, here\u0026rsquo;s a checklist for the discerning engineer:\nKnow Your Tools: Understand the differences between mutexes, semaphores, and other synchronization primitives. Profile, Profile, Profile: Don\u0026rsquo;t guess at performance bottlenecks. Use profiling tools to identify real issues. Keep It Simple: Complex synchronization schemes are bug magnets. Simplify where possible. Please\u0026hellip; KISS! Test Thoroughly: Concurrency bugs are notoriously hard to reproduce. Sometimes impossible to reproduce. So, be ready for 3am calls \u0026ndash; Ah, im sure it will go wrong.. Yup, very very sure\u0026hellip; Review and Refactor: Regularly review your concurrent code. What made sense yesterday might be a nightmare today. \u0026hellip;[spiderman quote playing in the background]\u0026hellip; Use these tools wisely, and please \u0026ldquo;understand\u0026rdquo; the difference before \u0026rsquo;trying\u0026rsquo; parallelism/threading/concurrency and may your code be ever race-condition free.\n","description":"Mutex vs Semaphore: The Lesser of Two Evils Mutexes and semaphores are like siblings in the synchronization primitives family — one a stickler for rules (mutex), the other more lenient but equally capable of chaos when misused (semaphore). I\u0026rsquo;ll try to dive into this family drama with a sprinkle of snark, to explore their strengths, weaknesses.. And, both drive me nuts when misused.\nThe Boring Theory Mutex A mutex, short for \u0026ldquo;mutual exclusion,\u0026rdquo; is like that one friend who insists on being the only one to use their fancy pen."},{"id":2,"href":"/blog/posts/","title":"Posts","parent":"a dystopian journey into the heart of tech","content":"","description":""},{"id":3,"href":"/blog/posts/biggest-problems/","title":"Biggest Problems","parent":"Posts","content":" A big picture perspective 😁 Two challenges at this point in time:\nNatural Stupidity Artificial Intelligence is there a cure for (1) 😕?\n","description":"A big picture perspective 😁 Two challenges at this point in time:\nNatural Stupidity Artificial Intelligence is there a cure for (1) 😕?"},{"id":4,"href":"/blog/posts/networking/","title":"Networking","parent":"Posts","content":" Net-work-ing, huh 😒 Networking is overrated. Become a person of value and the \u0026rsquo;network\u0026rsquo; will follow!\n","description":"Net-work-ing, huh 😒 Networking is overrated. Become a person of value and the \u0026rsquo;network\u0026rsquo; will follow!"},{"id":5,"href":"/blog/posts/clarity-in-radomness/","title":"Clarity in Radomness","parent":"Posts","content":" LinkedIn bios are\u0026hellip; well, seriously? Tough and wrong to generalize, but LinkedIn bios are seldom a joke. Having worked with quite a few over the last 16-17 years, some are absolutely terrible at tech, people skills, or most often both. But their LinkedIn profiles - oh my wow! On the contrary, those who are past the Dunning-Kruger curve have far less \u0026lsquo;shiny\u0026rsquo; LinkedIn bios, but these are people who can get things done. So, for all the headhunters/hiring managers, my 2c: it\u0026rsquo;s never vanilla; please look beyond profiles and background checks.\nCuriosity is the best guide. Somehow, it probably knows more than you do. Might sound meta, but most often, curiosity is worth paying attention to. One thing I\u0026rsquo;ve come to realize is that when I don\u0026rsquo;t know which path to choose, my \u0026lsquo;gut feeling\u0026rsquo; is to choose whatever is most exciting among the options I am able to contemplate. Excitement could mean different things to different people; to me, it\u0026rsquo;s the ability to keep me on my toes after the dust settles, and even if it\u0026rsquo;s not the most commercially lucrative option at the time, I\u0026rsquo;ve learned that pursuing that option anyway leads to a better me, which eventually yields dividends that are difficult to foresee sooner. TL;DR - go for the near-term if not super long-term over the short-term.\nAnxiety and burnout are real; they are a big deal, and it\u0026rsquo;s not often obvious. Recognizing when you\u0026rsquo;re starting to burn out or starting to get anxious is crucial. For me, it was noticing that I start to procrastinate; it\u0026rsquo;s usually a sign of burnout, as I\u0026rsquo;m generally enthusiastic about getting things done otherwise. What\u0026rsquo;s your cue? Saying \u0026ldquo;no\u0026rdquo; to anything non-critical in your off-time and setting healthy boundaries between work and the rest of your life is my 2c. I\u0026rsquo;m still not very good at this (yet), but I am learning and trying to shut off work after \u0026lsquo;work hours\u0026rsquo;. No reading emails, no Slack, no response to \u0026lsquo;dings\u0026rsquo; or whatever your mobile alerts sound. Putting things in perspective is surprisingly not done as frequently as one would hope. I\u0026rsquo;m trying to get better at asking - \u0026ldquo;Will this matter in two years?\u0026rdquo; I\u0026rsquo;ve been surprised at how often I answer \u0026rsquo;no\u0026rsquo;. It helps take the edge off the pressure. It allows me to miss a deadline every now and then without pushing myself too hard. Not every deadline is a do-or-die. In fact, most deadlines are not do-or-die in a work setting anyways �‍♂️\nNot every problem at work is mine to solve. I\u0026rsquo;ve learned this the hard way, but it\u0026rsquo;s also often common with personality types like me. I\u0026rsquo;m an INT-J \u0026amp; Enneagram Type 1, Wing 8. Chasing perfection is a recipe for shooting stress levels through the roof. It\u0026rsquo;s constant work to recognize what\u0026rsquo;s within my control and what\u0026rsquo;s not, but it\u0026rsquo;s important to keep a healthy equilibrium.\nHigh-functioning workaholism - I\u0026rsquo;m lucky to love what I do professionally. This means, along with my personality type (INT-J), I spend a lot of time doing \u0026rsquo;the work,\u0026rsquo; and often hours can fly by quickly. It\u0026rsquo;s tempting to say \u0026ldquo;just 5 more minutes,\u0026rdquo; and 5 hours later at 3 am, it\u0026rsquo;s \u0026ldquo;almost done.\u0026rdquo; Is that \u0026ldquo;dedication\u0026rdquo;? I once thought so too, but it\u0026rsquo;s simply poor self-control \u0026amp; planning. IMHO, it\u0026rsquo;s working stupid, not working hard.\nI did not truly believe in mind-body teamwork before; and kinda worked \u0026lsquo;stupid\u0026rsquo; (ref: High-functioning workaholism above). It was (and to an extent, still is) hard to break out of the vicious cycle, get things together, and see what is really capable. But, it\u0026rsquo;s asking this question - \u0026ldquo;Will this matter in 2 years\u0026rdquo; - that has helped me avoid spinning in the same hamster wheel. (Shameless plug - A tool that I use to keep me on the \u0026ldquo;think before ink\u0026rdquo; route, where I can repeatedly ask this question of - will it matter, is this tiny little application that I put together, which is a Pomodoro timer with a twist of accountability - Tomatick)\nYou need to be honest with yourself about the value that you are delivering to your org \u0026amp; what your replacement cost is. Many people provide negative value. They are terrible at their jobs and they bring the energy level down. They have a replacement cost of 0.\nAI will take a lot of jobs, but not people who give a damn about their craft.\nWhat I\u0026rsquo;d tell my past self, if time travel was real:\nYou are overly obedient. Not only doing what you are told to but find it hard to imagine any world other than the one they present to you. Spend time thinking about what you want, in isolation of the pressure of the world. There will be quiet periods of life. They feel slow and low in potential energy; the best use of them is to work on cool projects, write/blog more, and see improve your arsenal of tools. Few experiences are as joyful as cycling around a beautiful city on a sunny but cooler day. Don\u0026rsquo;t fall in love with something that can\u0026rsquo;t love you back. Companies do not spend a week crying when you break up with them. People will always have their opinions, most often, they could be unsolicited, snide, and rude too. One word - Ignore; this is usually a sign that they are deeply insecure. If they are in a position of authority over you, get away from them ASAP. You are more inclined to exit than to voice. It is better to do one than neither, but know that leaving is often expensive (not just monetarily; leaving could lead to starting from scratch, which might be fun once but gets taxing later). You get angry when you let people push past your boundaries. Stop letting them. Often, just saying \u0026rsquo;no\u0026rsquo; or \u0026lsquo;I\u0026rsquo;m out\u0026rsquo; is enough. Start tracking hours spent on deep work. It is an obvious and very visible metric of how much work you have done. Status exists in all domains. Status in areas you don\u0026rsquo;t care about is useless and mind-corroding. The best way to accumulate it in areas you care about is investing time, effort, and energy into it (p/t: side projects, blogs, tech talks). Be suspicious of people who fawn over you with affection for no reason. They usually have a system for finding people like you, and they will grind you up in the cogs of their machine. Don\u0026rsquo;t trust people when they say that they are experts and they know what they are doing. Ask the questions you need to ask to understand at least the high level of what is going on. People who lie to you about small and unimportant things will lie to you about big and important things. Most managers lie. Programming will only take you so far. Invest in writing and public speaking skills sooner than later. Consider deleting as often as you consider adding. This holds true for code, furniture \u0026amp; obligations. Fight bullshit and bureaucracy every time you see it and encourage other people to fight it too. Do not let the org chart get in the way of people working together productively. Nobody \u0026lsquo;owns\u0026rsquo; anyone. Don\u0026rsquo;t let anybody tell you what you can/can\u0026rsquo;t do. Outcomes are what count; don\u0026rsquo;t let a good process excuse bad results. Incentives are superpowers; set them carefully. Inspiration is perishable, and life goes by fast. Inaction is insidious. Get back up and keep going. It\u0026rsquo;s going to be ok, eventually. ","description":"LinkedIn bios are\u0026hellip; well, seriously? Tough and wrong to generalize, but LinkedIn bios are seldom a joke. Having worked with quite a few over the last 16-17 years, some are absolutely terrible at tech, people skills, or most often both. But their LinkedIn profiles - oh my wow! On the contrary, those who are past the Dunning-Kruger curve have far less \u0026lsquo;shiny\u0026rsquo; LinkedIn bios, but these are people who can get things done."},{"id":6,"href":"/blog/posts/memory-in-python/","title":"Oh, Python is slow?","parent":"Posts","content":"Sure, keep blaming the language like the rest of the herd — But if your code’s leaky and crawling, Spoiler: it’s you, not the language😏\nAh, another day, another developer blaming Python for their code\u0026rsquo;s sluggish performance. 🐌 Before you join the chorus of the uninformed, let\u0026rsquo;s embark on a journey through the labyrinthine world of Python\u0026rsquo;s memory management.\nThe Architect\u0026rsquo;s Dilemma: Designing a Programming Language Ever fantasized about creating your own programming language? Imagine having the power to decide how memory management works. Sounds thrilling, right? Or maybe just terrifying. It’s not just about keeping things simple or making them complex. Nope, it’s a constant tug-of-war between:\nKeeping interfaces idiot-proof Making sure it works on everything Balancing speed with not crashing all the time The brains behind Python have done most of the heavy lifting for you, so you don’t have to think too hard. But they’ve also left some decisions in the hands of the average coder. The real question is: how many even know what choices they\u0026rsquo;re making? And of those, how many are actually getting it right? Welcome to the can of worms you just opened.\nPeering Under the Hood: CPython\u0026rsquo;s Memory Allocation Time to roll up our sleeves and check out what’s under CPython’s hood. Curious how memory allocation works in C’s engine room? Meet the trio running the show:\nStatic memory allocation: The old-school, rock-solid type. Automatic memory allocation: The reliable workhorse, always on duty. Dynamic memory allocation: The nimble gymnast, ready to adapt on the fly. graph TD A[Memory Allocation in C] --\u0026gt; B[Static] A --\u0026gt; C[Automatic] A --\u0026gt; D[Dynamic] B --\u0026gt; E[Fixed size at compile time] C --\u0026gt; F[Stack-based, auto cleanup] D --\u0026gt; G[Heap-based, manual management] CPython, built on C\u0026rsquo;s rigid foundation, has its own set of hurdles. But things get interesting when Python’s design philosophy starts throwing wrenches into the mix:\nDynamically typed: Size? Who cares? We’ll figure it out when we get there. Dynamically sized core types: Lists, dictionaries, even integers – none of them have any clue about limits. Names as shape-shifters: some_value could be anything – an integer, a string, or even a list. It’s like Python’s version of a wild card. To manage this circus, CPython relies heavily on dynamic memory allocation. But don’t worry, it’s not as reckless as it sounds. Python added some fancy safety nets: garbage collection and reference counting. It’s like Python decided to handle the boring memory stuff for you. How thoughtful. (is this thanked enough, though?)\n# Example of dynamic typing and its impact on memory x = 5 # Initially an integer print(f\u0026#34;x is an integer: {x}, Size: {x.__sizeof__()} bytes\u0026#34;) x = \u0026#34;Hello\u0026#34; # Now a string print(f\u0026#34;x is now a string: {x}, Size: {x.__sizeof__()} bytes\u0026#34;) x = [1, 2, 3] # Now a list print(f\u0026#34;x is now a list: {x}, Size: {x.__sizeof__()} bytes\u0026#34;) The Triad of Allocation Domains Check out the three realms of memory allocation, each with its own gig:\nThe Raw Domain: For when you want to dive straight into system heap and manage big, non-object-related memory. Not for the faint-hearted. The Object Domain: Where Python objects hang out, blissfully ignorant of the underlying mess. The PyMem Domain: A throwback for those still using legacy APIs and penning letters by candlelight. CPython uses two types of allocators:\nmalloc: The OS\u0026rsquo;s basic tool for raw memory. pymalloc: Python’s custom allocator, designed for the PyMem and Object domains. CPython\u0026rsquo;s memory allocator, perched on top of malloc like a picky bird, has its own quirks:\nMost requests are small and fixed-size. PyObject? Just 16 bytes. PyASCIIObject? A lean 42 bytes. PyLongObject? A hefty 32 bytes. pymalloc handles blocks up to 256 KB. Larger chunks? They’re sent to malloc. Thread safety? Not needed with the GIL in play. pymalloc is like, “I’m good!” graph TD A[Memory Allocation Request] --\u0026gt; B{Size \u0026gt; 256 KB?} B --\u0026gt;|Yes| C[Raw Domain] B --\u0026gt;|No| D{Is it a Python Object?} D --\u0026gt;|Yes| E[Object Domain] D --\u0026gt;|No| F[PyMem Domain] C --\u0026gt; G[malloc] E --\u0026gt; H[pymalloc] F --\u0026gt; H The Holy Trinity: Blocks, Pools, and Arenas graph TD A[Arena 256KB] --\u0026gt; B[Pool] B --\u0026gt; C[Block] B --\u0026gt; D[Block] B --\u0026gt; E[Block] A --\u0026gt; F[Pool] F --\u0026gt; G[Block] F --\u0026gt; H[Block] I[Central Register] --\u0026gt; J[Tracks available blocks] I --\u0026gt; K[Manages pool usage] Blocks, the basic memory units, gather in pools. Pools are then grouped into arenas. It’s a bureaucratic dance of efficiency that would make any office manager proud.\nA central register, like a know-it-all librarian, keeps track of block locations and availability within each pool. When a pool runs out of space, the next one in line picks up the slack.\nArenas: The Grand Ballrooms of Memory Arenas, the big shots of memory grouping, are a hefty 256KB to match the system page size. Why? Because contiguous memory is faster than fragmented memory. It’s a nice theory, but how many developers actually care? I’m not counting on it.\nArenas are strung together in a doubly linked list within the arena data structure, using nextarena and prevarena pointers. It’s like a conga line of memory—minus the fun and dancing.\nPools: The Social Clubs of Memory Blocks Inside an arena, pools are created for block sizes up to 512 bytes, like a just-in-time memory buffet. If no pools are available for a requested size, a new one is added. Arenas keep track of pool creation with a high water mark.\nPools come in three types: Full, Used, and Empty. It’s like a memory nightclub—some are packed, some have space, and some are just waiting for action.\nEach pool has a doubly linked list to other pools of its class, like a social network for memory blocks—they always know where their buddies are.\nBlocks: The Individual Dancers in the Memory Ballet In a pool, memory is chopped up into fixed-size blocks, allocated and freed with the precision of a seasoned choreographer. Available blocks are tracked in a singly linked list called freeblock.\nWhen a block is freed, it’s shoved to the front of the freeblock list—like cutting in line, but perfectly acceptable in the realm of memory management.\nThe Object and PyMem Memory Allocation Domains The object memory allocator is the VIP lounge of the memory world, handling Python objects like dictionary keys and list items. It’s also the backstage pass for the compiler, AST, parser, and evaluation loop—where the real Python magic happens.\nFor those feeling rebellious and wanting to ditch the default strategy, you can create custom domain allocators or memory allocation sanitizers. But be warned: this isn’t for the faint of heart or the code-impaired. Know what you’re doing before you dive into this high-stakes game.\nReference Counting: Your Personal Memory Butler Now, let’s chat about reference counting—the unsung hero of Python’s memory management. It’s like having a butler who actually does their job, keeping track of your stuff and making sure it’s cleaned up properly.\nsequenceDiagram participant V as Variable participant O as Object participant RC as Reference Count V-\u0026gt;\u0026gt;O: Assign value O-\u0026gt;\u0026gt;RC: Increment count V-\u0026gt;\u0026gt;O: Reassign value O-\u0026gt;\u0026gt;RC: Decrement count RC-\u0026gt;\u0026gt;O: Count = 0 O-\u0026gt;\u0026gt;Memory: Free memory Every time you create an object, Python starts counting references—no, not your coding blunders (that’d be endless), but references to the object. When you assign a value to a variable, Python checks locals() and globals(), creates a new object if needed, and updates the relevant dictionary.\nIn CPython’s C source code, you’ll find Py_INCREF() and Py_DECREF() macros. These are the main tools for bumping up or down the reference count. It’s like a very dull, but crucial, game of ping pong.\nThis example demonstrates how Python keeps track of references and adjusts the count as references are added or removed:\nimport sys # Create a list a = [1, 2, 3] print(f\u0026#34;Reference count for \u0026#39;a\u0026#39;: {sys.getrefcount(a)}\u0026#34;) # Create another reference to the same list b = a print(f\u0026#34;Reference count after \u0026#39;b = a\u0026#39;: {sys.getrefcount(a)}\u0026#34;) # Remove one reference del b print(f\u0026#34;Reference count after \u0026#39;del b\u0026#39;: {sys.getrefcount(a)}\u0026#34;) Garbage Collection: Because Some People Can\u0026rsquo;t Clean Up After Themselves graph TD A[Create Objects] --\u0026gt; B[Objects Reference Each Other] B --\u0026gt; C[Delete External References] C --\u0026gt; D[Reference Count \u0026gt; 0] D --\u0026gt; E[Garbage Collector Runs] E --\u0026gt; F[Detect Circular References] F --\u0026gt; G[Break Cycles] G --\u0026gt; H[Free Memory] But what about those pesky circular references? You know, like when you do something silly like this:\nx = [] x.append(x) del x The reference count for x is still 1 because it referred to itself. It\u0026rsquo;s like a snake eating its own tail, but less mythological and more annoying.\nEnter the garbage collector—Python’s way of saying, “Alright, I’ll handle it.” It cleans up memory from objects that have outlived their usefulness. Enabled by default, it works in the background like a spectral janitor, tidying up without making a fuss.\ngraph TD A[Start GC] --\u0026gt; B[Find Unreachable Objects] B --\u0026gt; C[Mark as Garbage] C --\u0026gt; D[Free Memory] D --\u0026gt; E[Reset Counters] E --\u0026gt; F[End GC] The garbage collector doesn’t run constantly—because that’d be a CPU nightmare. Instead, it kicks in periodically after a certain number of operations. It’s like taking out the trash: you don’t do it every five minutes, but you also don’t wait until your place is buried in garbage.\nAnd here\u0026rsquo;s a concrete example of a circular reference: This example creates a circular reference that reference counting alone can\u0026rsquo;t handle, demonstrating the need for garbage collection.\nimport gc class Node: def __init__(self, name): self.name = name self.next = None # Create a circular reference node1 = Node(\u0026#34;Node 1\u0026#34;) node2 = Node(\u0026#34;Node 2\u0026#34;) node1.next = node2 node2.next = node1 # Remove references to the nodes del node1, node2 # Force garbage collection gc.collect() print(f\u0026#34;Garbage collector collected {gc.get_count()} objects\u0026#34;) Generational Garbage Collection: Because Even Trash Has a Lifecycle Python’s garbage collector uses generational garbage collection, based on the idea that most objects are short-lived. Like mayflies, but for memory.\nCPython’s collector has three generations, each with its own threshold for when to clean up. It’s like a trash lifecycle—starting with fresh garbage and eventually dealing with vintage refuse.\ngraph TD A[New Objects] --\u0026gt; B[Generation 0] B --\u0026gt;|Survive Collection| C[Generation 1] C --\u0026gt;|Survive Collection| D[Generation 2] B --\u0026gt;|Collected| E[Freed Memory] C --\u0026gt;|Collected| E D --\u0026gt;|Collected| E An example demonstrating generations GC:\nimport gc # Create some objects a = [1, 2, 3] b = \u0026#34;Hello, World!\u0026#34; c = {\u0026#34;key\u0026#34;: \u0026#34;value\u0026#34;} # Check garbage collection counts print(f\u0026#34;GC counts before collection: {gc.get_count()}\u0026#34;) # Force a collection gc.collect() print(f\u0026#34;GC counts after collection: {gc.get_count()}\u0026#34;) # Create more objects for _ in range(1000): list(range(100)) print(f\u0026#34;GC counts after creating many objects: {gc.get_count()}\u0026#34;) In Conclusion: A Mirror for the Masses So, next time you’re tempted to complain about Python’s performance, maybe take a moment for some self-reflection. Is it really Python that’s slow, or could it be that the fault lies not in the stars, but in ourselves?\nPython has made a heroic effort to simplify memory management. If your code still runs like a sloth in molasses, it might be time to look in the mirror and ask if the problem is right in front of the keyboard.\nRemember, a poor craftsman blames their tools. In Python’s world, that tool is often sharper than its user. So before you proclaim, “Python is slow,” ask yourself: Are you truly justified in casting that stone, or should you be hitting the books instead of bashing Python? 🤔💻\n","description":"Sure, keep blaming the language like the rest of the herd — But if your code’s leaky and crawling, Spoiler: it’s you, not the language😏\nAh, another day, another developer blaming Python for their code\u0026rsquo;s sluggish performance. 🐌 Before you join the chorus of the uninformed, let\u0026rsquo;s embark on a journey through the labyrinthine world of Python\u0026rsquo;s memory management.\nThe Architect\u0026rsquo;s Dilemma: Designing a Programming Language Ever fantasized about creating your own programming language?"},{"id":7,"href":"/blog/posts/battling-the-multiscreen-barrier/","title":"Barrier: The Underdog Triumph in a Proprietary World","parent":"Posts","content":" Multi-Screen Setups: battle stations, afterall. Right? \u0026#x1f609; I\u0026rsquo;m all about multi-monitor setups – and I\u0026rsquo;m talking way beyond just a couple of screens. \u0026#x1f601; Sure, I\u0026rsquo;ve had my share of neck strains from less than ideal arrangements, but that\u0026rsquo;s part of the fun, right? Experimenting until everything clicks. My current pride and joy? A setup with two ultrawide monitors, a slim ultrawide, and my laptop\u0026rsquo;s screen. Yep, that\u0026rsquo;s four screens in total.\nI\u0026rsquo;m firmly in the pro-MacBook camp (they just work, and no, 2024 still isn\u0026rsquo;t the year of Linux). But here\u0026rsquo;s a snag – the new Apple silicon machines, like the M1 MacBook Pro, have a frustrating limit on the number of external monitors they support. Apple\u0026rsquo;s stance? If you need more than two monitors, just shell out more cash for an \u0026lsquo;upgrade.\u0026rsquo; Thanks, but no thanks, Apple.\nSure, you could go down the DisplayLink route with compatible software and adapters, but let\u0026rsquo;s be real – it\u0026rsquo;s a suboptimal solution. DisplayLink just doesn\u0026rsquo;t cut it for me.\nSo, What\u0026rsquo;s My Idea of Optimal?\nThere are some proprietary tools out there, like Logitech\u0026rsquo;s Options+ with its \u0026lsquo;Flow\u0026rsquo; feature. It\u0026rsquo;s neat if you\u0026rsquo;ve got the right hardware. You can navigate across screens connected to different machines with just one keyboard and mouse, making it feel like they\u0026rsquo;re all part of one big system. They even support some sort of natural-feeling copy-paste between machines.\nBut, mind you – the \u0026rsquo;natural\u0026rsquo; part of this setup is a bit of a stretch. It can be clunky and rough around the edges.\nEnter Barrier. This isn\u0026rsquo;t just Logitech\u0026rsquo;s \u0026lsquo;Flow\u0026rsquo; on steroids; it\u0026rsquo;s faster, more versatile, and supports almost every OS you can think of. This open-source gem lets you control multiple computers with a single keyboard and mouse setup – think of it as the universal remote for all your screens. The GitHub readme is pretty much self explanatory (and you should definitely check it out \u0026#x1f60e;).\nA huge shoutout to all the contributors of Barrier. Here\u0026rsquo;s to the champions of #FOSS! \u0026#x1f389;\n","description":"Multi-Screen Setups: battle stations, afterall. Right? \u0026#x1f609; I\u0026rsquo;m all about multi-monitor setups – and I\u0026rsquo;m talking way beyond just a couple of screens. \u0026#x1f601; Sure, I\u0026rsquo;ve had my share of neck strains from less than ideal arrangements, but that\u0026rsquo;s part of the fun, right? Experimenting until everything clicks. My current pride and joy? A setup with two ultrawide monitors, a slim ultrawide, and my laptop\u0026rsquo;s screen. Yep, that\u0026rsquo;s four screens in total."},{"id":8,"href":"/blog/posts/people-the-problem/","title":"People the Problem","parent":"Posts","content":" Smart-ass complex, not giving a shit \u0026amp; incompetence There\u0026rsquo;s no short of snarky, condescending tech articles out there, sometimes they are pure BS but often they are an attempt to paint the \u0026ldquo;picture\u0026rdquo; in black and white by some frustrated programmer. Stumbled upon Dimitry\u0026rsquo;s take - incompetent people are the problem, while we are strangers, his words struck a chord.\nI resonate with these bits from Dimitry\u0026rsquo;s article \u0026amp; PS: all views are my own.\nThe smart-ass complex\nKnowing how to code or open a terminal and use git grep doesn’t make you smart nor educated. Not being smart is totally fine. We just need to avoid being stupid. And we need to be humble and not let our egos blind us. If we recognise we aren’t smart, we can start going back to basics by keeping it simple. If we aren’t smart enough to predict future problems, we shouldn’t even try. Instead, let’s solve the problems at hand as they come and do our best at keeping things clean and flexible Not giving a shit\nHaving a “no fucks given” culture is a disease. It poisons everything around it. At some point everyone stops trying to improve things. They simply go with the flow. Not owning stuff creates bigger snowballs. People don’t care and sometimes people are unable to confirm crappy code isn’t shitty for a reason. Incompetence\nIf someone’s used hammers and nails all their life and you give them screws and a screwdriver, they’ll simply say “oh that’s a pretty crappy hammer but the job is a job” and proceed to smashing the screw into the wood with the handle. If you want them to use it properly, invest in their education or at least handhold them until proficient. Do people do that? Less often than one would expect. And don’t forget teams where the tech leads have no idea what they’re doing either. Incompetent people hire other incompetent people who then get involved in hiring. It’s exponential. If you don’t care about the company, care about yourself. And speak up Don’t worry about the company’s success if your skin is not in the game. Think about your own comfort. What could we change so you felt a bit better? Identify those problems and speak up He also talks about what is his version of \u0026ldquo;competence\u0026rdquo;, that part is nice too.. mostly text book. Things that we as professional programmers should live and breath. Do we? Well, that\u0026rsquo;s an article for another day. Ciao for now 👋\n","description":"Smart-ass complex, not giving a shit \u0026amp; incompetence There\u0026rsquo;s no short of snarky, condescending tech articles out there, sometimes they are pure BS but often they are an attempt to paint the \u0026ldquo;picture\u0026rdquo; in black and white by some frustrated programmer. Stumbled upon Dimitry\u0026rsquo;s take - incompetent people are the problem, while we are strangers, his words struck a chord.\nI resonate with these bits from Dimitry\u0026rsquo;s article \u0026amp; PS: all views are my own."},{"id":9,"href":"/blog/posts/whats-with-points/","title":"Point estimations and Sprints, huh","parent":"Posts","content":" Yet another post about software estimations - shouldn\u0026rsquo;t it either be 1 point or NFI (No **** Idea) There are things that engineers - especially software folk do well, we nail some really hard intangible problems on its head and boy, it feels good to build something ground up or cleanup a pile of mess. But, this group, almost holistically suck at one thing - that is estimation.\nSoftware engineers are notoriously poor estimators (well, its my blog so this is my view anyways). As an industry, we are not poor performers, although it may seem that way, because the prediction of performance is poor. There are many reasons why we set unreasonable expectations, and few will deny that estimating is a complex task. When performance doesn\u0026rsquo;t meet the estimate, there are two possible causes: poor performance or poor estimates. In the software world, we have ample evidence that our estimates stink, but virtually no evidence that people in general don\u0026rsquo;t work hard enough or intelligently enough.\nThe impact goes far beyond cost overruns and missed deadlines. The typical approach to estimates ends up forcing bad behavior while privileging vanity metrics over delivering actual business value.\nAgile or Sprints to be precise correlates with Noise IMHO In Agile environments, estimates are often based on story points and velocity. What can be so complex about creating a discrete piece of software anyways and in this age of almost AGI, right? Well, if everything goes to \u0026ldquo;plan\u0026rdquo; and the GPTs were truly replacing human in the loop, sure - estimations should truly reflect velocity. But, its never been a perfect world and last time I checked, the promised utopia is still far fetched.\nThis obsession with specifying and measuring the full process in advance wraps a plus or minus variance around a system that views engineers as machines pushing predictable work products through a pipeline at a steady stream. Yet to state what should be obvious, human beings are not machines. (Thank god! 😑) And maybe less obviously, the complexity of any non-trivial software engineering task is almost impossible to accurately estimate in advance. This probably leads to - shouldn\u0026rsquo;t we make non-trivial, \u0026hellip;. more trivial? True, we should. And, for that, in true agile spirit, we create more tickets and assign points to these \u0026lsquo;spike\u0026rsquo; tickets? Isn\u0026rsquo;t that brilliant 😂\nSprints are where all of the issues with agile software dev really come from. Constant arbitrary, meaningless deadlines that serve no purpose but create rushes, tech debt, missed “commitments” that serve as a meaningless metric to use against teams while made commitments give no benefit.\nSprints lead to meetings that attempt to plan better rather than actually getting work done. Nothing wrong with deadlines and drawing a line in the sand, they can infact serve a sense of motivation to get things done. However, with sprint ceremonies, often there is this \u0026lsquo;calling\u0026rsquo; - measure everything you can which builds the idea that estimation is a skill that can easily be improved. That, is a \u0026lsquo;cute wishful thinking\u0026rsquo; 😆, maybe a utopian fallacy? sure, you can learn to be less widely off, and this too is extremely contextual - it depends on skills \u0026amp; strengths of individuals that make a team. But, nooooo - we want to measure \u0026lsquo;velocity\u0026rsquo;. What usually happens is that quality get shitty and corners get cut, and you get the product at the correct deadline, but it\u0026rsquo;s not the same that you wanted to ship before development started (even if the features are nominally there).\nWhats with velocity? Isnt that a thing for cars, rockets and stuff? One of the most common pre-requisites to sprints is estimating tasks (or so called \u0026ldquo;user stories\u0026rdquo; – what a name!). There are many different ways to do it, but the most common way I\u0026rsquo;ve seen is:\nhave the whole team (💸) discuss the task at hand and agree on estimation (planning poker - and, people get paid to play this during work hours 😳) use a certain set of numbers to represent estimation values. This includes the works! Fibonacci series, t-shirt sizes and some creative minds also use tree viz to estimate tickets! So, the outcome is some sorta key-value pairs, where every task has \u0026lsquo;points\u0026rsquo; and these numbers are meant to represent \u0026hellip; something for someone or to everyone\u0026hellip;? This number is also supposedly a \u0026lsquo;guiding\u0026rsquo; principle for how much we can get done in x weeks/months - whatever is the sprint \u0026lsquo;cycle\u0026rsquo; ♻️.\nAnd, at the end of every sprint the objective is to look at the tasks that were delivered, they add up the number of the points of each task, and end up with a single number. This number represents how \u0026ldquo;fast\u0026rdquo; the team is going. It\u0026rsquo;s a single number that represents all the team\u0026rsquo;s work over a few months, and this number can be used to measure whether the team speeds up or slows down. Its often also used to compare performance of individual developers, to see who\u0026rsquo;s driving the team\u0026rsquo;s performance and who\u0026rsquo;s lagging behind. Magic ✨ right?\n\u0026hellip; Well, absolute 💩. Velocity can provide value, but the way it\u0026rsquo;s often used by Agile aficionados and inexperienced managers ruins the value of this metric. Why am I the antagonist here? Because:\n🕞 My time !== Your time Points correlates with time. Time to finish the task. Developers are asked to predict how much time a task will take them. So 1 point might be a proxy for half a day, or a day. Then 2 points are 2 days, 5 points are a week. But, for some reason, the obvious here seem to be not so obvious - how much time I need to complete a task is different than how much time you need 😒.\nSome teams try to workaround this by assigning the tasks before estimating, and during estimation they ask \u0026ldquo;how much time it will take this specific developer to complete the task?\u0026rdquo; This approach is so bad it deserves its own article, but just to mention its biggest sin – it shifts from team-oriented to individual-oriented work, where everyone only cares about the tasks they have assigned to their name, instead of caring about all the tasks the team committed to.\n🚀 More !== Better Velocity = speed + direction, and the faster we move the better, no? Well yes, for cars, rockets and stuff yes. But, we are software programmers - i.e. human beings. Expecting developers to increase velocity over time contradicts the whole idea of estimating the complexity of tasks.\nThe base of this wrong assumption is that as the team gets better, they will deliver more value over time. And that\u0026rsquo;s true, the team will build similar things faster, hence they will achieve more in the same span of time. But at the same time, as the team gets better and builds more sophisticated software, they will give lower estimations to similar tasks.\nVelocity of the team over time should reach plateau and stay roughly the same, not grow (unless the team gets more people).\n🏭 Quantity !== Quality When a measure becomes a target, it ceases to be a good measure - Goodhart\u0026rsquo;s law\nGetting more done in a sprint, if that is \u0026lsquo;incentivised\u0026rsquo;, what that means is that the team will start inflating numbers, giving larger and larger values to the same type of tasks over time, just to show that the line on the velocity chart always goes up.\nIf the only measurement of success is velocity, then nothing else matters. Quality? Who cares, approve that Pull Request and let\u0026rsquo;s go! Bug fixes? Only if a bug is assigned a number of points, otherwise it goes to the bottom of the backlog. The team works long hours and can\u0026rsquo;t keep it going for long? Doesn\u0026rsquo;t matter, the velocity must go up!\n📍 1 point or NFI IMO, for the majority of software development tasks, it\u0026rsquo;s binary - it\u0026rsquo;s either a trivial task that the individual or team (depending on their strengths, past experience or ability to get things done) is sure about, or it\u0026rsquo;s complex enough that we\u0026rsquo;re venturing into the unknown. I like to call it the \u0026ldquo;1 or NFI\u0026rdquo; approach - it\u0026rsquo;s either 1 point, or No **** Idea.\nThe amount of unpredictability and volatility inherent to our job makes an accurate estimate almost a contradiction in terms. Is it a bug? Oh, it could be a walk in the park, or a deep rabbit hole of despair. New feature? Could be a few lines of code, or a total cluster**** of interdependent systems. Refactoring? Could take a day or two, or you might open a Pandora\u0026rsquo;s box that makes you wish for a career change.\nSo, am I advocating for no planning, but reckless and procrastination friendly workplace? Maybe not. Understandably, the need for ballpark figure to help the business plan its strategy, set expectations and all that jazz is \u0026hellip; you know - understandable. But, my point here is - why are we forcing a sham precision on an inherently fuzzy problem in the name of adopting agile? If we know it\u0026rsquo;s a trivial task, sure - give it a 1 point. But if it\u0026rsquo;s a non-trivial task, it\u0026rsquo;s NFI. It\u0026rsquo;s like trying to measure the surface of the ocean with a ruler - it\u0026rsquo;s just the wrong tool for the job.\nStuck with an NFI task? Find the \u0026lsquo;doer(s)\u0026rsquo; in your workplace and attempt to break it down (if possible). In other words, try and turn the NFI task into something that we can confidently say is a 1 point. It\u0026rsquo;s moot to bring the whole team to \u0026rsquo;estimate\u0026rsquo; these tasks where John doe \u0026amp; John snow can talk about their opinions non-stop while the others browse through their instagram / tik-tok / threads / twitter / x whatever else is the thing they find amusing 🔫\nWhen we throw out the illusion of precision, we can actually focus on delivering value. With the 1 or NFI approach, we get rid of useless discussions about whether it should be a 2 or a 3. Instead, we can focus on problem-solving, on understanding what we don\u0026rsquo;t know and figuring out how to know it. We can give meaningful updates to our stakeholders: \u0026ldquo;we\u0026rsquo;re still figuring out how to solve this\u0026rdquo; is a lot more meaningful than \u0026ldquo;it\u0026rsquo;s 80% done\u0026rdquo; for the third week in a row.\nIn the end, the 1 or NFI approach is not just about estimates. It\u0026rsquo;s about facing the reality of software development: it\u0026rsquo;s complex, it\u0026rsquo;s unpredictable, and it\u0026rsquo;s hard. And, please stop playing poker with \u0026lsquo;sprints\u0026rsquo; 🎲\n","description":"Yet another post about software estimations - shouldn\u0026rsquo;t it either be 1 point or NFI (No **** Idea) There are things that engineers - especially software folk do well, we nail some really hard intangible problems on its head and boy, it feels good to build something ground up or cleanup a pile of mess. But, this group, almost holistically suck at one thing - that is estimation.\nSoftware engineers are notoriously poor estimators (well, its my blog so this is my view anyways)."},{"id":10,"href":"/blog/posts/database-is-sacred/","title":"Database Is Sacred","parent":"Posts","content":" Database is Sacred: An \u0026ldquo;Engineer\u0026rsquo;s\u0026rdquo; Testament What does the word \u0026lsquo;database\u0026rsquo; make you think of? It\u0026rsquo;s probably difficult to generalize, but I\u0026rsquo;m guessing a good chunk of you would think of a \u0026lsquo;relational\u0026rsquo; flavor. Well, there\u0026rsquo;s no shortage of \u0026lsquo;flavors\u0026rsquo; among databases today, and I feel like talking — or venting — about how often relational databases are used beneath their potential today\n(Relational) Databases are awesome My (not so distant) future self will probably negate this title😁, but for the purpose of this blog or the context in my head today, yes - relational databases are awesome. They are sturdy and efficient enough to do what you need them to do: store and manipulate data. Yes, I said manipulate.\nDuring the past decade or two, the development of new frameworks and ORMs has led us to treat databases as \u0026ldquo;bags to store data in.\u0026rdquo; Most tutorials are one-dimensional, urging us to put all business logic in the same place (your backend/API layer). Sometimes this works fine; other times, it is slower than a pack of snails. This slowdown doesn’t happen immediately, and we usually figure it out only when it\u0026rsquo;s too late to revert poor decisions. You write a function that processes some simple data, stores the result in the database, and displays it to the user. Fifty change requests later, we have a 500-line function, doing nested loops through data to calculate the tax amount. And the function that once completed the job in a millisecond now takes 20 minutes to run.\nPicture this: a blank canvas, a fresh project, the excitement of architecting a brand-new system. Two schools of thought emerge: database-driven development (let\u0026rsquo;s call this DbDD, because DDD would upset the domain 😬) versus application code-driven development (and let\u0026rsquo;s call this ACDD. Porque no). And of course, there are \u0026lsquo;full stack developers,\u0026rsquo; right? (coughs, JavaScript). I did some digging and apparently, the idea of a \u0026ldquo;full stack\u0026rdquo; developer has been around since the early 2000s, and it\u0026rsquo;s steadily gaining momentum as a standard in the startup sphere. With nearly a third of developers considering themselves full-stackers, the term has become one of the most popular hiring buzzwords of the decade. Again, it\u0026rsquo;s tough to generalize, but I would argue that this concept is nebulous and is potentially one of the reasons for \u0026rsquo;tech debt\u0026rsquo; as that fresh project/idea starts to become real. And here\u0026rsquo;s my attempt to shed some light on how, in the name of delivering rapid value, our \u0026lsquo;full stack developers\u0026rsquo; often cut corners and lead that \u0026lsquo;brand-new system\u0026rsquo; into becoming (pardon my French) a pile of garbage.\nMany (take this with a grain of salt; I know it\u0026rsquo;s wrong to generalize) full-stack developers are lured by the hypnotic allure of ACDD. It\u0026rsquo;s the shiny new car that entices with the promise of speed. With its application-first, think-later approach, it boasts an illusion of rapid development. The element that\u0026rsquo;s surprisingly overlooked here is that a database comes with many pre-packed features, ready to use. But, no, it\u0026rsquo;s the \u0026lsquo;higher-order functions\u0026rsquo; that take precedence ¯_(ツ)_/¯. Here\u0026rsquo;s my take on how we let it slip.\nSchema is a thing I\u0026rsquo;ll talk through an arbitrary example of an e-commerce startup (it\u0026rsquo;s always e-commerce in examples, somehow ¯_(ツ)_/¯). When designing an application schema, it\u0026rsquo;s all too easy to take the path of least resistance with ACDD, defining users and orders tables, and then throwing in some JSON columns for flexibility:\nCREATE TABLE orders ( id SERIAL PRIMARY KEY, user_id INT NOT NULL, order_content JSON NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ); We might expect the order_content to be an array of items, each with an itemId and quantity:\n[ { \u0026#34;itemId\u0026#34;: 1, \u0026#34;quantity\u0026#34;: 3 }, { \u0026#34;itemId\u0026#34;: 2, \u0026#34;quantity\u0026#34;: 2 } ] While this approach gives you the illusion of progress, it will soon lead to a dead-end. JSON fields in PostgreSQL (😫) aren\u0026rsquo;t as performant for querying as proper relational tables. Searching within JSON fields, filtering data, or maintaining consistency and integrity within a JSON field can quickly become a nightmare😵.\n(\u0026lsquo;Full-stack development\u0026rsquo; is all about embracing JavaScript, right? In that spirit, I\u0026rsquo;ll use TypeScript for the application code examples here.) The ACDD approach forces you to handle complex and error-prone parsing and validation of JSON fields:\ninterface OrderContent { itemId: number; quantity: number; } async function handleNewOrder(userId: number, orderContent: OrderContent[]) { const orderContentJson = JSON.stringify(orderContent); await db.query( \u0026#34;INSERT INTO orders (user_id, order_content) VALUES ($1, $2)\u0026#34;, [userId, orderContentJson] ); } Without a contract for the JSON column, nothing stops a developer from inserting inconsistent data, such as an item without a quantity or even non-item data:\n[ { \u0026#34;itemId\u0026#34;: 3 }, { \u0026#34;itemId\u0026#34;: 4, \u0026#34;quantity\u0026#34;: \u0026#34;two\u0026#34; }, { \u0026#34;message\u0026#34;: \u0026#34;This is not an item.\u0026#34; } ] Inconsistencies here lead to runtime errors. However, a \u0026lsquo;full-stack dev\u0026rsquo; who wants to handle this in the application layer might approach it like this:\ninterface OrderContent { itemId: number; quantity: number; } async function handleNewOrder(userId: number, orderContent: any[]) { // Validate orderContent if (!Array.isArray(orderContent)) { throw new Error(\u0026#34;Invalid orderContent: must be an array.\u0026#34;); } const validatedOrderContent: OrderContent[] = []; for (const item of orderContent) { if (typeof item.itemId !== \u0026#39;number\u0026#39; || typeof item.quantity !== \u0026#39;number\u0026#39;) { throw new Error(\u0026#34;Invalid item: must have an itemId and a quantity.\u0026#34;); } validatedOrderContent.push(item); } const orderContentJson = JSON.stringify(validatedOrderContent); await db.query( \u0026#34;INSERT INTO orders (user_id, order_content) VALUES ($1, $2)\u0026#34;, [userId, orderContentJson] ); } That right there is the first turn towards a \u0026lsquo;pile of garbage\u0026rsquo;. The point is, before assigning JSON or, worse, TEXT type to house unstructured data in a table of your relational database, consider if that\u0026rsquo;s your cue to adopt normalization.\nSo, what could and should be the alternative approach? (Looks at DbDD). Simple - use your database to its strength. In this case, normalize instead of relying on the JSON type.\nCREATE TABLE IF NOT EXSITS orders ( id SERIAL PRIMARY KEY, user_id INT NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ); CREATE TABLE IF NOT EXSITS items ( id SERIAL PRIMARY KEY, name VARCHAR(100) NOT NULL, price NUMERIC(6,2) NOT NULL, category_id INT NOT NULL ); CREATE TABLE IF NOT EXSITS order_items ( order_id INT NOT NULL, item_id INT NOT NULL, quantity INT NOT NULL, PRIMARY KEY(order_id, item_id), FOREIGN KEY (order_id) REFERENCES orders (id) ON DELETE CASCADE, FOREIGN KEY (item_id) REFERENCES items (id) ON DELETE CASCADE ); 💥 Food for thought: Don\u0026rsquo;t overlook modelling schema and rush to \u0026lsquo;dump\u0026rsquo; data that you can handle \u0026rsquo;later\u0026rsquo;.\nSQL - Embrace it, way around it is chaotic Unintentionally, I think ORMs are often perceived as a way to avoid touching SQL 😠. Don\u0026rsquo;t get me wrong, ORMs (especially mature products like Hibernate or Entity Framework) are great, handling a lot of underlying complexity and security. But those too, like everything else, are \u0026rsquo;tools\u0026rsquo;. A tool is meant to be used for a task or set of tasks, and unfortunately, it\u0026rsquo;s not a magic wand.\nSome frameworks (looking at Ruby on Rails) even go to the extent of being database agnostic, where you could easily work on multiple database systems in different environments. Consider having SQLite for your development and test environments, and PostgreSQL as your deployment environment. This approach, in my humble opinion, is another turn that leads to a \u0026lsquo;pile of garbage\u0026rsquo;. I am a proponent of embracing the data layer for its strengths; abstracting it would be a mistake leading to the loss of some of the most important features a database has to offer.\nWhile various ORMs have abstracted SQL away from developers, SQL has become some esoteric super language (which it isn\u0026rsquo;t) that\u0026rsquo;s reserved for wizards (which it\u0026rsquo;s not). SQL is super simple and easy to learn. What it allows us to do is manipulate the data at the source.\nWhen you are writing your data processing on the database itself, you can think less about N+1 issues or memory bloats because you\u0026rsquo;re instantiating every record under the sun to sum a few columns on them. On the contrary, ACDD often relies on the application layer for processing data. Continuing from the e-commerce example, if you need to find the top-selling items, you might fetch all the orders and items into your application and then process them using loops and conditionals:\ninterface ItemCount { itemId: number; count: number; } async function getTopSellingItems(): Promise\u0026lt;ItemCount[]\u0026gt; { const res = await db.query(\u0026#34;SELECT order_content FROM orders\u0026#34;); const orderContents: OrderContent[][] = res.rows.map((row) =\u0026gt; JSON.parse(row.order_content)); const itemCounts: { [itemId: number]: number } = {}; for (const orderContent of orderContents) { for (const { itemId, quantity } of orderContent) { if (!itemCounts[itemId]) { itemCounts[itemId] = 0; } itemCounts[itemId] += quantity; } } return Object.entries(itemCounts) .map(([itemId, count]) =\u0026gt; ({ itemId: parseInt(itemId), count })) .sort((a, b) =\u0026gt; b.count - a.count); } Here, we\u0026rsquo;re looping over all order_contents and keeping a count of itemId quantities. This approach involves excessive data transfer from the database to the application, relatively high memory usage, and increased CPU usage due to application-side processing.\nThat entire TypeScript logic can be condensed into this single SQL query:\nSELECT oi.item_id, SUM(oi.quantity) as total_quantity FROM order_items oi GROUP BY oi.item_id ORDER BY total_quantity DESC LIMIT 5; This SQL query performs aggregation on the database side, returning only the final result to the application, which leads to a much more efficient use of resources. The corresponding application code then becomes incredibly simple:\ninterface ItemCount { itemId: number; count: number; } async function getTopSellingItems(): Promise\u0026lt;ItemCount[]\u0026gt; { const res = await db.query( \u0026#34;SELECT oi.item_id, SUM(oi.quantity) as total_quantity FROM order_items oi GROUP BY oi.item_id ORDER BY total_quantity DESC LIMIT 5\u0026#34; ); return res.rows.map((row) =\u0026gt; ({ itemId: row.item_id, count: row.total_quantity })); } 💥 Food for thought: Perform data ops closest to the source - which is the database. Don\u0026rsquo;t fall for fetch first, filter later approach.\nMigrations - Time machines are real Migrations are an essential part of every database-centric application. They represent the changes made to your database over time and serve as the source of truth for your database schema. Their importance cannot be overstated. In my opinion, there are three crucial aspects to the migration process: auditability, avoidance of fragmentation, and accounting for the source of truth.\nAuditability Auditability implies that every change to the database schema is tracked in the form of migrations, which are version-controlled. You should be able to answer questions such as \u0026ldquo;Who made a particular change?\u0026rdquo; and \u0026ldquo;When was this change made?\u0026rdquo; by looking at the migrations.\nWhile the primary role of migrations is to encapsulate the changes made to the database schema, there\u0026rsquo;s more to it - migrations should also handle data changes within a migration.\nTo highlight the importance of auditability, let\u0026rsquo;s consider an anti-pattern where a developer manually adds a new column to the database without a migration, but by connecting to the database directly 😈:\nALTER TABLE orders ADD COLUMN delivery_address TEXT; While this change is quick and easy, it introduces a host of problems. There is no record of who made the change, when it was made, or why it was made. When deploying the application to a new environment, the new column will be missing, potentially leading to runtime errors.\nThis change should instead be a migration (choose a migration agent of your preference, my current personal preference is sqitch), with every deployment having a corresponding revert, tracked in source control.\nAvoiding Fragmentation Migration fragmentation refers to the practice of having many small, piecemeal migrations, each making minor changes to the database. This practice can lead to a disorganized codebase and can make understanding the evolution of the database schema difficult.\nConsider an example where a developer creates three separate migrations to add a new table, add a column to it, and then add an index to that column. In this case, these changes are spread across multiple migrations in the filesystem, potentially combined with other unrelated changes:\n-- Version: 1 CREATE TABLE orders ( id SERIAL PRIMARY KEY, user_id INT NOT NULL, created_at TIMESTAMP NOT NULL DEFAULT CURRENT_TIMESTAMP ); -- Version: 2 ALTER TABLE orders ADD COLUMN delivery_address TEXT; -- Version: 3 CREATE INDEX idx_orders_delivery_address ON orders(delivery_address); Choice of your migration agent plays a pivotal role in avoiding fragmentation. Rework in sqitch or update in liquibase are some great tools to help avoid fragmentation.\nMaintaining source of truth Migrations serve as the source of truth for your database schema. They define the state of your database at any given point in time, and this state should be the same regardless of the environment (development, staging, or production).\nTo maintain this source of truth, migrations need to be both deterministic and idempotent. Being deterministic means the migration will produce the same result given the same input. Being idempotent means you can run the migration multiple times without changing the result beyond the initial application.\nConsider an example where a developer creates a migration to add a unique index to a column:\nCREATE UNIQUE INDEX idx_users_email ON users(email); If the users table contains duplicate email addresses, this migration will fail. What\u0026rsquo;s even worse is if the migration is run on a table without duplicate emails, and then run again after duplicates have been introduced, the results will be inconsistent.\nA better approach would be to handle potential duplicates within the migration:\nDELETE FROM users WHERE id IN ( SELECT id FROM ( SELECT id, ROW_NUMBER() OVER(partition BY email ORDER BY id) AS rnum FROM users ) t WHERE t.rnum \u0026gt; 1 ); CREATE UNIQUE INDEX idx_users_email ON users(email); This migration first removes duplicate email addresses and then creates the unique index. The migration is deterministic (it always results in a table where email addresses are unique) and idempotent (it can be run multiple times without causing errors or inconsistencies).\n💥 Food for thought: Schema (\u0026amp; potentially data only) changes to database are best placed to run as migrations. Migrations should be auditable, avoid fragmentation \u0026amp; be the source of truth.\nTransactions must be ACID Transactions are another critical aspect of working with a database, and they\u0026rsquo;re often overlooked in the ACDD approach. When an operation involves multiple steps, all of which must either succeed or fail together, they should be included in a single transaction. This ensures that the database remains in a consistent and predictable state. Consistently handling data is of paramount importance in any database-centric application, and ACID (Atomicity, Consistency, Isolation, Durability) transactions are the mechanism for achieving this.\nThis concept is better explained with a banking or payments example rather than an e-commerce example. Or maybe it\u0026rsquo;s just that payments are my thing, so I\u0026rsquo;ll go with a payments example. It\u0026rsquo;s my blog, right? 😎\nImagine a banking system where you need to transfer money from Account A to Account B. This operation consists of two separate actions: deducting from the balance of Account A and crediting to the balance of Account B.\nA Non-ACID Approach: The Road to Inconsistency In a non-transactional, or non-ACID approach, these two actions would be performed separately:\nasync function transferFunds(sourceId: number, targetId: number, amount: number) { // Reduce balance of source account await db.query( \u0026#34;UPDATE accounts SET balance = balance - $1 WHERE id = $2\u0026#34;, [amount, sourceId] ); // Increase balance of target account await db.query( \u0026#34;UPDATE accounts SET balance = balance + $1 WHERE id = $2\u0026#34;, [amount, targetId] ); } But what happens if the operation fails right after the first query 💩? What if there\u0026rsquo;s a server crash, a network failure, or an error in the second query? This could lead to a situation where the balance was deducted from Account A, but not credited to Account B. It\u0026rsquo;s a data integrity nightmare: the total balance across the system has suddenly decreased. In a real-world banking system, this would mean that money has simply disappeared!💫\nThe ACID Approach: Ensuring Consistency In an ACID transactional approach, we perform the two actions within a single transaction:\nasync function transferFunds(sourceId: number, targetId: number, amount: number) { // Begin the transaction await db.query(\u0026#34;BEGIN\u0026#34;); try { // Reduce balance of source account const res1 = await db.query( \u0026#34;UPDATE accounts SET balance = balance - $1 WHERE id = $2 RETURNING balance\u0026#34;, [amount, sourceId] ); // If the source account doesn\u0026#39;t have enough funds, throw an error if (res1.rows[0].balance \u0026lt; 0) { throw new Error(\u0026#34;Insufficient funds\u0026#34;); } // Increase balance of target account await db.query( \u0026#34;UPDATE accounts SET balance = balance + $1 WHERE id = $2\u0026#34;, [amount, targetId] ); // Commit the transaction await db.query(\u0026#34;COMMIT\u0026#34;); } catch (error) { // If there\u0026#39;s any error, rollback the transaction await db.query(\u0026#34;ROLLBACK\u0026#34;); throw error; } } Here, we initiate a transaction using the BEGIN command, then attempt to perform the two actions. If there\u0026rsquo;s an error (such as insufficient funds in the source account, or a network issue), we catch it and roll back the transaction using the ROLLBACK command. This action undoes all changes made within the transaction, preserving the consistency of our database.\nIf both actions are successful, we commit the transaction using the COMMIT command. This step finalizes the changes made in the transaction. Regardless of any subsequent failures, the money will be correctly and atomically transferred from Account A to Account B, thereby maintaining the integrity of our data.\n💥 Food for thought: Data integrity is pivotal, interactions with database must account for ACID compliance \u0026amp; transactions are your friends.\nStored Procedures: Server-side Powerhouse Another underappreciated feature of databases includes stored procedures and functions. With ACDD, developers often neglect these elements, preferring to execute corresponding logic within the application code instead.\nConsider a scenario where there\u0026rsquo;s a need to update the stock quantity after placing an order. An ACDD developer might approach this task as follows:\ninterface Order { userId: number; items: Array\u0026lt;{itemId: number, quantity: number}\u0026gt;; } async function placeOrder(order: Order) { const client = await db.connect(); try { await client.query(\u0026#39;BEGIN\u0026#39;); const orderId = await createOrder(client, order.userId); for (const item of order.items) { await createOrderItem(client, orderId, item.itemId, item.quantity); await updateStock(client, item.itemId, -item.quantity); } await client.query(\u0026#39;COMMIT\u0026#39;); } catch (e) { await client.query(\u0026#39;ROLLBACK\u0026#39;); throw e; } finally { client.release(); } } In this instance, the transaction logic and error handling are explicitly executed in the application layer. While this offers flexibility, it simultaneously adds to the complexity of the application.\nOn the other hand, a DbDD approach might leverage stored procedures. The aforementioned transaction could be managed through a stored procedure like this:\nCREATE OR REPLACE PROCEDURE place_order(user_id INT, order_items_order_id INT, item_id INT, quantity INT) LANGUAGE plpgsql AS $$ BEGIN INSERT INTO orders(user_id) VALUES(user_id) RETURNING id INTO order_id; FOR item IN order_items LOOP INSERT INTO order_items(order_id, item_id, quantity) VALUES(order_id, item.item_id, item.quantity); UPDATE items SET stock = stock - item.quantity WHERE id = item.item_id; END LOOP; COMMIT; EXCEPTION WHEN OTHERS THEN ROLLBACK; RAISE; END $$; And, the app code becomes:\nasync function placeOrder(order: Order) { await db.query(\u0026#39;CALL place_order($1, $2, $3, $4)\u0026#39;, [...]); } 💥 Food for thought: By using stored procedures, the complexity of the transaction logic is moved into the database. Your application code becomes cleaner and more focused on its primary responsibilities.\nViews - They are cheap, but effective If not carefully handled, manipulating data to meet specific presentation requirements can lead to bloated and disorganized code in your application layer. This scenario frequently arises when adopting an ACDD approach. To elaborate, well, here goes an e-commerce example, \u0026hellip;again:\nImagine we need to compile a summary of each user\u0026rsquo;s orders, including the total number of orders placed, total quantity of items ordered, and the total amount spent.\nUsing the ACDD approach, one might retrieve all the orders for a user, loop through them, and reduce the orders array to calculate these totals. This process necessitates considerable data processing within the application code:\ninterface Order { quantity: number; price: number; } async function getUserOrderSummary(userId: number) { const orders = await Order.findAll({ where: { userId: { [Op.eq]: userId } } }); let orderCount = 0; let totalQuantity = 0; let totalAmount = 0; orders.forEach(order =\u0026gt; { orderCount++; totalQuantity += order.quantity; totalAmount += order.quantity * order.price; }); return { orderCount, totalQuantity, totalAmount, }; } This could instead be:\nCREATE VIEW user_order_summary AS SELECT user_id, COUNT(*) AS order_count, SUM(quantity) AS total_quantity, SUM(quantity * price) AS total_amount FROM orders GROUP BY user_id; And in the application code, we could simply do this (irrespective of the ORM):\nasync function getUserOrderSummary(userId: number) { const [result] = await db.query(\u0026#34;SELECT * FROM user_order_summary WHERE user_id = $1\u0026#34;, { replacements: [userId], type: db.QueryTypes.SELECT, }); return result; } 💥 Food for thought: Leverage views to account for navigating away from complex app code data wrangling.\nMat. Views - Escaping the ORM overhead Another frequent pitfall of ACDD architectures is an overemphasis on the application layer to carry out demanding computational tasks. Although the ease of ORM libraries might lure you into managing everything within your application layer, this practice can cause performance bottlenecks and lead to code that is difficult to maintain.\nLet\u0026rsquo;s consider another e-commerce example. Suppose we need a comprehensive report of the top-selling products over the past month. This report should include the product\u0026rsquo;s ID, name, total sales count, total revenue, and the average order value for each product.\nThe ACDD approach might appear like this:\nimport { Sequelize, Op, literal } from \u0026#34;sequelize\u0026#34;; async function getTopSellingProducts() { const oneMonthAgo = new Date(); oneMonthAgo.setMonth(oneMonthAgo.getMonth() - 1); // Fetch the products const products = await Product.findAll({ include: [{ model: OrderItem, include: [{ model: Order, where: { createdAt: { [Op.gte]: oneMonthAgo } } }] }] }); // Prepare the report const report = products.map(product =\u0026gt; { const sales_count = product.orderItems.reduce((total, orderItem) =\u0026gt; total + orderItem.quantity, 0); const total_revenue = product.orderItems.reduce((total, orderItem) =\u0026gt; total + (orderItem.quantity * product.price), 0); const avg_order_value = total_revenue / sales_count; return { id: product.id, name: product.name, sales_count, total_revenue, avg_order_value }; }); // Sort and limit the report report.sort((a, b) =\u0026gt; b.sales_count - a.sales_count); return report.slice(0, 10); } This approach marks another detour towards a \u0026lsquo;pile of garbage\u0026rsquo; because it leads to performance overhead, extended load times during peak traffic, and burdensome maintenance requirements for the code.\nWhat could be a better alternative? Offloading computational tasks to the database, especially for heavy data processing tasks that aren\u0026rsquo;t time-sensitive. This is where the strength of PostgreSQL\u0026rsquo;s materialized views comes into play. Unlike regular views, materialized views store their result set as a physical table in the database and can be indexed for faster access. Here\u0026rsquo;s how we could implement the same report using a materialized view:\nCREATE MATERIALIZED VIEW top_selling_products AS SELECT p.id, p.name, COUNT(*) as sales_count, SUM(oi.quantity * p.price) as total_revenue, AVG(oi.quantity * p.price) as avg_order_value FROM products p JOIN order_items oi ON oi.product_id = p.id JOIN orders o ON o.id = oi.order_id WHERE o.created_at \u0026gt;= NOW() - INTERVAL \u0026#39;1 month\u0026#39; GROUP BY p.id, p.name ORDER BY sales_count DESC LIMIT 10; Fetching the report becomes a straightforward, highly efficient operation:\nasync function getTopSellingProducts() { return db.query(\u0026#34;SELECT * FROM top_selling_products\u0026#34;, { type: db.QueryTypes.SELECT, }); } This alternative accounts for performance, data manipulation at source, increased user experience, less application code overhead.\n💥 Consider materialized views computationally heavy tasks, refresh mat. views with a background task.\nRules - becuase, they are good 😱 The PostgreSQL rule system provides a powerful tool for automatic, database-level responses to specific events. However, developers using an ACDD approach often overlook these capabilities, instead opting to handle such actions in the application code.\nImagine a scenario where, for auditing purposes, your application needs to keep a log of all order creation events. This audit log is a record in a separate audit_log table for each insertion into the orders table.\nIn an ACDD approach using an ORM like Sequelize, you might handle this within your application code:\nimport { Sequelize, Transaction } from \u0026#39;sequelize\u0026#39;; async function createOrder(userId: number, itemId: number, quantity: number) { const transaction = await sequelize.transaction(); try { // Insert into the orders table await Order.create({ userId: userId, itemId: itemId, quantity: quantity }, { transaction }); // Insert into the audit_log table await AuditLog.create({ action: \u0026#39;INSERT\u0026#39;, tableName: \u0026#39;orders\u0026#39;, userId: userId, actionTime: new Date() }, { transaction }); await transaction.commit(); } catch (error) { await transaction.rollback(); throw error; } } Perfectly functional approach, but risks data integrity, potentially leading to reduced performance since the audit log insertion in the application layer adds an extra network round trup and a potential point of failure.\nA better alternative? In DbDD approach, we could use the database\u0026rsquo;s inherent capabilities to maintain data integrity. In PostgreSQL, we can achieve the desired behavior using rules. Let\u0026rsquo;s create a rule that automatically inserts into the audit_log table whenever a new row is inserted into the orders table:\nCREATE OR REPLACE RULE order_audit_log AS ON INSERT TO orders DO INSERT INTO audit_log (action, table_name, user_id, action_time) VALUES (\u0026#39;INSERT\u0026#39;, \u0026#39;orders\u0026#39;, NEW.user_id, NOW()); With this rule in place, inserting an order becomes a simple operation:\nasync function createOrder(userId: number, itemId: number, quantity: number) { await db.query( \u0026#34;INSERT INTO orders (user_id, item_id, quantity) VALUES ($1, $2, $3)\u0026#34;, [userId, itemId, quantity] ); } Isn\u0026rsquo;t that simplified application logic, guaranteed data integrity and performance?\nA few more often overlooked database features: Harnessing Indices: Indexing is a database technique that accelerates data retrieval operations on a database table. Much like the index found at the end of a book, it allows the database to find data without scanning the entire table. Here are several crucial points to bear in mind for effective index use:\nPinpointing Frequent or Slow Queries: Indices aren\u0026rsquo;t a universal solution, and they should be customized to your specific use-cases. A common strategy is to scrutinize your application logs to identify which queries are executed most frequently and which ones take an extended time to run. Adding indices to cater to these specific operations can significantly boost your application\u0026rsquo;s performance.\nGrasping Data Distribution: An index\u0026rsquo;s effectiveness hinges on the data distribution in your table. If a column has a high degree of variance (i.e., the data in the column is extremely diverse), an index on that column can substantially quicken query performance. However, if the data is predominantly homogeneous (i.e., there are numerous repeating values), the advantages of indexing dwindle.\nUsing Partial Indexes for Specific Queries: PostgreSQL allows the creation of partial indices, where an index is built on a subset of data that meets a certain criterion. This can be a significant boon when your queries typically involve a specific subset of data.\nCreating Multicolumn Indices: PostgreSQL enables the creation of an index on multiple columns. This can be beneficial when your queries frequently involve filtering or sorting on these columns simultaneously. However, the sequence of columns in this index matters as it influences the queries that the index can expedite.\nHandling Index Maintenance and Overhead: While indices can hasten data retrieval, they entail some overhead. They consume extra disk space and make write operations slower because each insert, update, or delete operation also requires an index update. Therefore, it\u0026rsquo;s crucial to strike a balance and avoid over-indexing your tables.\nUtilizing Table Partitioning: Table partitioning is a strategy where a table is divided into smaller, more manageable segments, and each piece of data is inserted into the appropriate partition. This technique can significantly enhance performance, simplify maintenance, and provide faster query execution by allowing the system to scan less data. Here are some key insights on when and where to use table partitioning:\nSizeable Tables: Partitioning is most potent for tables that are large and would ordinarily take a substantial time to query.\nPredetermined Access Patterns: If the table data features a column often used in where clauses and exhibits a good distribution of values, it could be an ideal candidate for partitioning.\nData Age: If older data in the table is infrequently accessed, then range partitioning on a date/time column can be extremely effective. This also facilitates the efficient implementation of data retention policies, where old partitions can be quickly dropped.\nMaintenance Operations: Partitioning can accelerate maintenance operations. For instance, dropping a partition (which is a metadata operation) is much faster than deleting rows from a table (which necessitates individual row deletion and generates undo and redo logs).\nPreferring FTS over LIKE: Full-text search (FTS) is a technique employed for searching text content. It transcends the capabilities of traditional pattern-matching commands like LIKE and ILIKE, offering a more potent and flexible toolkit for text-based searches. Here are several tips on effective use:\nNatural Language Search: Full-text search interprets the search text as a natural language query, considering language-specific features such as stemming, synonyms, etc., to deliver more pertinent results.\nRelevance Ranking: Results can be ranked not merely on whether they match the search terms, but on the degree of match. You can customize the ranking function to suit your needs.\nComplex Query Capabilities: Full-text search supports intricate queries including Boolean operators, phrase searching, and proximity searching.\nPerformance: Full-text search can be much swifter than LIKE and ILIKE for extensive text fields as it uses a tsvector data type for efficient text analysis.\nCustomizable Parsing and Indexing: Full-text search allows customization in how text is parsed and indexed, including support for different languages and configurations.\nConclusion Well, firstly, that was a bit of a brain dump and an outlet for some pent-up frustration 😤.\nEmbracing Database-Driven Development means viewing your database as more than just a storage system — it\u0026rsquo;s a high-performance powerhouse for data processing, a sentinel for your business logic, a time capsule of your application\u0026rsquo;s history, and so much more. Database-driven development urges you to unleash the full potential of your database system, whether it\u0026rsquo;s PostgreSQL or another robust RDBMS. From harnessing the capabilities of SQL, migrations, and stored procedures to mastering the science of performance monitoring and optimization, DbDD covers a broad range of practices and concepts. When applied correctly, these can significantly enhance your application architecture.\nAre you rushing to \u0026lsquo;finish\u0026rsquo; a full-stack application? PLEASE, pause and reflect before donning your \u0026lsquo;full stack developer\u0026rsquo; cap. As with everything else in real life, \u0026lsquo;strong foundations\u0026rsquo; are pivotal to the long-term success of your project or product. And in the realm of software systems, nothing is more foundational than your database. Treat your database with reverence, not as a landfill 😏.\n","description":"Database is Sacred: An \u0026ldquo;Engineer\u0026rsquo;s\u0026rdquo; Testament What does the word \u0026lsquo;database\u0026rsquo; make you think of? It\u0026rsquo;s probably difficult to generalize, but I\u0026rsquo;m guessing a good chunk of you would think of a \u0026lsquo;relational\u0026rsquo; flavor. Well, there\u0026rsquo;s no shortage of \u0026lsquo;flavors\u0026rsquo; among databases today, and I feel like talking — or venting — about how often relational databases are used beneath their potential today\n(Relational) Databases are awesome My (not so distant) future self will probably negate this title😁, but for the purpose of this blog or the context in my head today, yes - relational databases are awesome."},{"id":11,"href":"/blog/posts/we-have-a-problem/","title":"We Have a Problem","parent":"Posts","content":" The Reality of Imaginary Problems - In the context of Software Many factors lead to ineffective software development: from the tools used, to team communication, to the personal motivation of developers, the testing approach to the organisational leadership matrix. Among these, there\u0026rsquo;s a fundamental issue that often results in poorly conceived software: chasing perceived or, more often than not, non-existent problems, that take shape through the process to prove some kinda relevance by one or many involved directly or indirectly in the process.\nLet me double click on the last part - non-existent problems. Most complicated or broken software is not designed to be overly complex or dysfunctional. It’s just designed to do something other than its intended purpose.\nConsider a situation where you are a \u0026lt;fancy title here\u0026gt; developer working in a media company that runs a music streaming platform. They need a custom backend system that can handle the delivery of music albums, videos, and blogs, generate advertising revenue, and sell promotional products.\nThe system\u0026rsquo;s requirements might include:\nQuick server response times in \u0026lt;a region\u0026gt;, along with real-time streaming and downloading capabilities for podcasts. System stability ensuring that it doesn’t crash or freeze for 99.99 percent of users, ideally never. Compatibility with Google AdWords and potential integration with other third-party ad providers. Real-time linking and updating of the product catalog from \u0026lt;music erp store\u0026gt;, possibly with personalized recommendations based on user consumption history. Integration with Facebook Live or even an in-house live streaming solution if feasible. These requirements distill through many layers of management before they reach your team - the team of developers. There will be course of development with \u0026lsquo;regular checkin\u0026rsquo; including these layers in your org and all seems well. Yet, when your team delivers the MVP a few months later, it\u0026rsquo;s far from what the original requirements craved for💩. The application hangs on startup, the advertising selection interface is counter-intuitive, twitter product links are broken, and the Facebook Live stream is sluggish🔥.\nYou as a developer are astonished becuase, the prioritized items that were due for delivery - according to the person \u0026lt;fancy title here\u0026gt; who distilled the requirements to your team were:\nA sophisticated recommendation system. Real-time transcript generation of all streams. Ultra-fast loading times across the globe. A proprietary streaming protocol to replace Facebook Live. A feature to easily integrate with more than 20 ad exchanges. So, you\u0026rsquo;re effectively part of a team who has \u0026lsquo;delivered\u0026rsquo;, but considered a failure 👿. Go figure 😨. Understandably, you \u0026amp; your team is confused \u0026amp; angry, rightfully so, becuase you\u0026rsquo;ve gone to hell and back to deliver this on time!\nThe problem lies in the misinterpretation of the original objectives. The development team prioritized non-essential, exciting technical challenges over the core, functional requirements. This misalignment may be further amplified when communication between the team and stakeholders gets filtered through multiple layers (coughs product managers, project managers, delivery managers, and \u0026lt;fancy title\u0026gt; managers), each adding their own interpretation of what\u0026rsquo;s needed 💩.\nImaginary problems are often more fun to solve than real ones. Extremely intelligent people play competitive games, construct and solve problems, and write books that aim to answer abstract questions about the human condition, all of them for free. A mediocre programmer, however, will probably charge you a fair amount to build a simple Android app. That’s not because mediocre programmers are harder to find than geniuses, but because the former activities are all fun, while the latter can be quite boring.\nHow many imaginary problems a software developer can create depends on their imagination and the complexity of the real problems they are tasked with. This is not unique to developers. Other departments like sales, HR, legal, and even accounting have their own ways of creating imaginary problems. These arise when individuals overemphasize minor issues related to their roles or take on more responsibilities than necessary, just to prove their relevance.\nOne dark aspect of this phenomenon is that the existence of imaginary problems can be used as a means of justifying team or organizational growth. An example is the banking industry. Despite the technological advancements, online banking software is often complex and cumbersome, a reflection of the industry\u0026rsquo;s hierarchy and its resistance to change. Not because the task of transferring and storing numbers is hard, but because addressing the real issues might threaten job security and established order.\nImaginary problems often stem from boredom or from long communication chains. When requirements pass through multiple individuals, even with the best of intentions, misinterpretations and alterations are inevitable. Sometimes, these changes happen due to misunderstandings or a desire to make tasks more exciting.\nWhen the real problems get lost and replaced by imaginary ones, complex software solutions arise. This often happens when boring tasks are ignored in favor of more challenging and \u0026lsquo;interesting\u0026rsquo; problems. But this results in software that does not meet the needs of the end users and wastes time and resources.\nThe dark force There can often be an even darker reason for the existence of imaginary problems: problems can help a team or a company grow, and can even become an integral part of its function.\nEver heard about the trio of IT experts who realized that maintaining online banking security wasn\u0026rsquo;t as herculean as perceived? They engineered a foolproof banking application from scratch, harnessing functional design principles and memory safe languages, and began transitioning major banks to their impeccable framework.\nProbably not, because such a trio doesn\u0026rsquo;t exist. Yet, there are numerous developer teams, struggling to understand basic principles such as \u0026ldquo;rollbacks,\u0026rdquo; consistently creating banking software.\n\u0026ldquo;It\u0026rsquo;s a challenge to make a person understand something when their livelihood depends on their ignorance of it!\u0026rdquo; — Upton Sinclair\nSeeding imaginary problems and accounting for complex software that solves for these imaginary problems - sure, that\u0026rsquo;s one way to claim \u0026lsquo;busy\u0026rsquo; and \u0026lsquo;percieved\u0026rsquo; progress or \u0026lsquo;useless\u0026rsquo; celebration, but how does something like go unnoticed? Isn\u0026rsquo;t this basic common sense 😵?\nWell, isnt this is kinda similar to -\nThe boardroom often turns a blind eye to the management indulging in \u0026ldquo;conference trips\u0026rdquo; involving exotic locations and generous allowances for \u0026ldquo;miscellaneous\u0026rdquo; expenses. In return, the management overlooks the board\u0026rsquo;s less than transparent practices. Encouraged by department heads to maintain an image of perfection, management turns a blind eye to those spending more on their office decor and personal assistants than necessary. Because supervisors don\u0026rsquo;t question their grandiose power displays, department heads ignore those supervisors who, instead of reducing overheads, focus on creating impressive presentations. Because team leaders don\u0026rsquo;t complain about their superiors\u0026rsquo; lack of understanding of basic software, supervisors ignore the team leaders discussing complex system integration instead of addressing slow response times. Team leaders, not recognizing that their bosses barely understand coding, don\u0026rsquo;t question their developers who, instead of diagnosing the slow server response times, keep overhauling the user interface using the latest JavaScript frameworks. It\u0026rsquo;s a vicious cycle of tackling non-existent problems—from the CEO who doesn\u0026rsquo;t understand that securing another big investor won\u0026rsquo;t compensate for customer dissatisfaction, to the software intern who doesn\u0026rsquo;t realize that redesigning the booking interface won\u0026rsquo;t solve the issue of overbooking.\nBut everyone keeps trying to solve these imaginary problems, because if they stop and focus on the real problems, they might realize the whole system is fundamentally flawed 😇.\n","description":"The Reality of Imaginary Problems - In the context of Software Many factors lead to ineffective software development: from the tools used, to team communication, to the personal motivation of developers, the testing approach to the organisational leadership matrix. Among these, there\u0026rsquo;s a fundamental issue that often results in poorly conceived software: chasing perceived or, more often than not, non-existent problems, that take shape through the process to prove some kinda relevance by one or many involved directly or indirectly in the process."},{"id":12,"href":"/blog/posts/pipelines/","title":"Pipelines","parent":"Posts","content":" Serverless Data Pipelines: AWS Glue is a potential future poster figure; maybe not just yet! Data engineering plays a pivotal role in the success of organizations, especially those that are data-driven. It can make or break an organization\u0026rsquo;s growth. Data pipelines form the foundation of data engineering. However, the term \u0026ldquo;pipeline\u0026rdquo; has become somewhat clichéd in software engineering, as it can mean different things depending on the context and significance of the tasks involved.\nIn computing, a pipeline, also known as a data pipeline, is a set of data processing elements connected in series, where the output of one element is the input of the next one. The elements of a pipeline are often executed in parallel or in time-sliced fashion. Some amount of buffer storage is often inserted between elements\nWe’re talking about big data, Hadoop, and data pipelines — that should and will lead to Spark. Spark is a one-stop solution for a variety of big data problems, a unified platform for batch, real-time(almost), machine learning, deep learning, and Graphs.\nMore\n","description":"Serverless Data Pipelines: AWS Glue is a potential future poster figure; maybe not just yet! Data engineering plays a pivotal role in the success of organizations, especially those that are data-driven. It can make or break an organization\u0026rsquo;s growth. Data pipelines form the foundation of data engineering. However, the term \u0026ldquo;pipeline\u0026rdquo; has become somewhat clichéd in software engineering, as it can mean different things depending on the context and significance of the tasks involved."},{"id":13,"href":"/blog/posts/logs/","title":"Logs","parent":"Posts","content":" Centralized logging \u0026amp; log analytics in a busy, distributed environment Logs play a crucial role in any system, providing valuable insights into your application\u0026rsquo;s behavior, system activities, and the causes of errors. It is essential to efficiently monitor these logs to ensure your system is functioning as expected. In case something goes wrong, you need to quickly identify the issue, understand what happened, and take preventive measures to avoid its recurrence.\nIf you\u0026rsquo;re operating in a distributed and scalable infrastructure like Kubernetes and haven\u0026rsquo;t given much attention to log management, it\u0026rsquo;s vital to address it as early as possible. Why, you ask?\nConsider the lifecycle of Kubernetes pods. These pods are managed by the Kubernetes cluster and can be restarted or rescheduled at any time. Relying on ephemeral pod volumes to capture logs is not a reliable approach, as these volumes can be lost, and recovery becomes impossible.\nHorizontal scaling is undoubtedly advantageous. However, monitoring each individual server separately becomes an anti-pattern. To effectively monitor logs regardless of scale and volume, it\u0026rsquo;s crucial to have a centralized location where all logs can be consolidated.\nIn an event-based architecture, logs play a pivotal role in understanding the state of your system. Without a mechanism to correlate these events, you may find yourself lost in a sea of data with no way to navigate.\nCentralized logging addresses these concerns and more. However, designing a robust centralized logging system can be complex, requiring a deep understanding of all the moving parts. This article sheds light on the key aspects involved in centralizing logs in a distributed environment.\nNumerous tools are available to assist in achieving this goal. In this article, we focus on the fluent ecosystem for log tailing, log analytics using Loki, and visualization with Grafana. Moreover, we highlight some common pitfalls that can save you hours of debugging and frustration.\nMore\n","description":"Centralized logging \u0026amp; log analytics in a busy, distributed environment Logs play a crucial role in any system, providing valuable insights into your application\u0026rsquo;s behavior, system activities, and the causes of errors. It is essential to efficiently monitor these logs to ensure your system is functioning as expected. In case something goes wrong, you need to quickly identify the issue, understand what happened, and take preventive measures to avoid its recurrence."},{"id":14,"href":"/blog/posts/ethereact/","title":"Ethereact","parent":"Posts","content":" ETHEReact: Build a Full Stack Decentralized E-Commerce App, Deploy to Ethereum Virtual Machine \u0026amp; Interact using ReactJS TL;DR This article is not an in-depth explanation of Blockchain or a marketing pitch for Crypto.\nInstead, this article is intended to guide developers and blockchain enthusiasts in building an end-to-end prototype on the blockchain. By the end of this article, you will have constructed a basic decentralized e-commerce platform.\nThroughout the article, you will write two contracts in Solidity (one for the supplier and another for the customer), compile and migrate your contract to the EVM (Ethereum Virtual Machine), create a simple ReactJS frontend, and connect your frontend to the EVM using web3.js.\nMore\n","description":"ETHEReact: Build a Full Stack Decentralized E-Commerce App, Deploy to Ethereum Virtual Machine \u0026amp; Interact using ReactJS TL;DR This article is not an in-depth explanation of Blockchain or a marketing pitch for Crypto.\nInstead, this article is intended to guide developers and blockchain enthusiasts in building an end-to-end prototype on the blockchain. By the end of this article, you will have constructed a basic decentralized e-commerce platform.\nThroughout the article, you will write two contracts in Solidity (one for the supplier and another for the customer), compile and migrate your contract to the EVM (Ethereum Virtual Machine), create a simple ReactJS frontend, and connect your frontend to the EVM using web3."},{"id":15,"href":"/blog/categories/","title":"Categories","parent":"a dystopian journey into the heart of tech","content":"","description":""},{"id":16,"href":"/blog/tags/","title":"Tags","parent":"a dystopian journey into the heart of tech","content":"","description":""}]